{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Load Dataset from Azure ML**\n",
        "Now that my dataset \"Banking_Customer\" is properly uploaded and registered in Azure ML, I will:\n",
        "1. Connect to the Azure ML Workspace.\n",
        "2. Retrieve the dataset using Dataset.get_by_name().\n",
        "3. Convert it into a Pandas DataFrame.\n",
        "4. Display the first few rows to verify that the dataset is loaded correctly.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Connect to Azure ML Workspace\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# Load dataset (Ensure the dataset name matches exactly)\n",
        "dataset = Dataset.get_by_name(ws, name=\"Banking_Customer\")\n",
        "\n",
        "# Convert dataset directly to Pandas DataFrame\n",
        "df = dataset.to_pandas_dataframe()\n",
        "\n",
        "# Display first few rows to verify loading\n",
        "df.head()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'infer_column_types': 'False', 'activity': 'to_pandas_dataframe'}\n{'infer_column_types': 'False', 'activity': 'to_pandas_dataframe', 'activityApp': 'TabularDataset'}\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "   customer_id  credit_score country  gender  age  tenure    balance  \\\n0     15634602           619  France  Female   42       2       0.00   \n1     15647311           608   Spain  Female   41       1   83807.86   \n2     15619304           502  France  Female   42       8  159660.80   \n3     15701354           699  France  Female   39       1       0.00   \n4     15737888           850   Spain  Female   43       2  125510.82   \n\n   products_number  credit_card  active_member  estimated_salary  churn  \n0                1            1              1         101348.88      1  \n1                1            0              1         112542.58      0  \n2                3            1              0         113931.57      1  \n3                2            0              0          93826.63      0  \n4                1            1              1          79084.10      0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>credit_score</th>\n      <th>country</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>tenure</th>\n      <th>balance</th>\n      <th>products_number</th>\n      <th>credit_card</th>\n      <th>active_member</th>\n      <th>estimated_salary</th>\n      <th>churn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15634602</td>\n      <td>619</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>2</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101348.88</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15647311</td>\n      <td>608</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>41</td>\n      <td>1</td>\n      <td>83807.86</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112542.58</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15619304</td>\n      <td>502</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>8</td>\n      <td>159660.80</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113931.57</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15701354</td>\n      <td>699</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>39</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93826.63</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>15737888</td>\n      <td>850</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>43</td>\n      <td>2</td>\n      <td>125510.82</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>79084.10</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1740605784449
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Data Preprocessing - Handle Missing Values**\n",
        "Missing values in a dataset can lead to incorrect model predictions. \n",
        "We will check for missing values and handle them by:\n",
        "- Filling missing numerical values with the column mean.\n",
        "- Dropping rows with missing categorical values.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values per column:\\n\", df.isnull().sum())\n",
        "\n",
        "# Fill missing numerical values with column mean (avoid warning)\n",
        "df.fillna(df.mean(numeric_only=True), inplace=True)\n",
        "\n",
        "# Drop rows with missing categorical values (if any)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Verify if missing values are handled\n",
        "print(\"Missing values after handling:\\n\", df.isnull().sum())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Missing values per column:\n customer_id         0\ncredit_score        0\ncountry             0\ngender              0\nage                 0\ntenure              0\nbalance             0\nproducts_number     0\ncredit_card         0\nactive_member       0\nestimated_salary    0\nchurn               0\ndtype: int64\nMissing values after handling:\n customer_id         0\ncredit_score        0\ncountry             0\ngender              0\nage                 0\ntenure              0\nbalance             0\nproducts_number     0\ncredit_card         0\nactive_member       0\nestimated_salary    0\nchurn               0\ndtype: int64\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1740606098027
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Convert Categorical Data to Numeric**\n",
        "Machine learning models require numerical data. We will:\n",
        "- Encode categorical variables (e.g., Gender, Geography) into numerical form.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Column Names in Dataset:\\n\", df.columns)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Column Names in Dataset:\n Index(['customer_id', 'credit_score', 'country', 'gender', 'age', 'tenure',\n       'balance', 'products_number', 'credit_card', 'active_member',\n       'estimated_salary', 'churn'],\n      dtype='object')\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1740606304321
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical variables into numeric\n",
        "\n",
        "# Encoding 'gender' (lowercase in dataset)\n",
        "df['gender'] = df['gender'].map({'Male': 0, 'Female': 1})\n",
        "\n",
        "# Encoding 'country' (instead of 'Geography')\n",
        "df['country'] = df['country'].astype('category').cat.codes  \n",
        "\n",
        "# Verify changes\n",
        "df.head()\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "   customer_id  credit_score  country  gender  age  tenure    balance  \\\n0     15634602           619        0       1   42       2       0.00   \n1     15647311           608        2       1   41       1   83807.86   \n2     15619304           502        0       1   42       8  159660.80   \n3     15701354           699        0       1   39       1       0.00   \n4     15737888           850        2       1   43       2  125510.82   \n\n   products_number  credit_card  active_member  estimated_salary  churn  \n0                1            1              1         101348.88      1  \n1                1            0              1         112542.58      0  \n2                3            1              0         113931.57      1  \n3                2            0              0          93826.63      0  \n4                1            1              1          79084.10      0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>credit_score</th>\n      <th>country</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>tenure</th>\n      <th>balance</th>\n      <th>products_number</th>\n      <th>credit_card</th>\n      <th>active_member</th>\n      <th>estimated_salary</th>\n      <th>churn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15634602</td>\n      <td>619</td>\n      <td>0</td>\n      <td>1</td>\n      <td>42</td>\n      <td>2</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101348.88</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15647311</td>\n      <td>608</td>\n      <td>2</td>\n      <td>1</td>\n      <td>41</td>\n      <td>1</td>\n      <td>83807.86</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112542.58</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15619304</td>\n      <td>502</td>\n      <td>0</td>\n      <td>1</td>\n      <td>42</td>\n      <td>8</td>\n      <td>159660.80</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113931.57</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15701354</td>\n      <td>699</td>\n      <td>0</td>\n      <td>1</td>\n      <td>39</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93826.63</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>15737888</td>\n      <td>850</td>\n      <td>2</td>\n      <td>1</td>\n      <td>43</td>\n      <td>2</td>\n      <td>125510.82</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>79084.10</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1740606450503
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Feature Selection**\n",
        "Not all columns are useful for churn prediction. We will:\n",
        "- Select only relevant features for training.\n",
        "- Drop unnecessary columns like Customer ID, Name, etc.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select relevant features and target variable (using correct column names)\n",
        "X = df[['credit_score', 'age', 'balance', 'products_number', 'active_member']]\n",
        "y = df['churn']  # Correct target column name\n",
        "\n",
        "# Display selected features\n",
        "X.head()\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "   credit_score  age    balance  products_number  active_member\n0           619   42       0.00                1              1\n1           608   41   83807.86                1              1\n2           502   42  159660.80                3              0\n3           699   39       0.00                2              0\n4           850   43  125510.82                1              1",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>credit_score</th>\n      <th>age</th>\n      <th>balance</th>\n      <th>products_number</th>\n      <th>active_member</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>619</td>\n      <td>42</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>608</td>\n      <td>41</td>\n      <td>83807.86</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>502</td>\n      <td>42</td>\n      <td>159660.80</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>699</td>\n      <td>39</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>850</td>\n      <td>43</td>\n      <td>125510.82</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1740606632485
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Split Data into Training & Testing Sets**\n",
        "To evaluate our model, we divide our dataset into:\n",
        "- Training Set (80%): Used to train the machine learning model.\n",
        "- Testing Set (20%): Used to check the model’s accuracy.\n",
        "This helps in understanding how well the model performs on unseen data.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split  \n",
        "\n",
        "# Split data into training (80%) and testing (20%)  \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  \n",
        "\n",
        "# Display dataset shapes\n",
        "print(f\"Training data: {X_train.shape}, Testing data: {X_test.shape}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Training data: (8000, 5), Testing data: (2000, 5)\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1740606800310
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Train a Machine Learning Model**\n",
        "I will use Logistic Regression, a simple and effective model for predicting churn.\n",
        "The model learns patterns from training data and makes predictions on unseen customers.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression  \n",
        "\n",
        "# Train the Logistic Regression model  \n",
        "model = LogisticRegression()  \n",
        "model.fit(X_train, y_train)  \n",
        "\n",
        "print(\"Model training completed.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1740606861885
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression on scaled data\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Model training completed.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model training completed.\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1740606926371
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7: Evaluate Model Performance**\n",
        "Once the model is trained, we will:\n",
        "- Measure accuracy\n",
        "- Generate a classification report (precision, recall, and F1-score)\n",
        "- Check the ROC Curve to understand performance\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report  \n",
        "\n",
        "# Make sure X_test is scaled before predicting\n",
        "y_pred = model.predict(X_test_scaled)  # Use the scaled version!\n",
        "\n",
        "# Print accuracy and classification report  \n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))  \n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Accuracy: 0.8105\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.82      0.97      0.89      1607\n           1       0.57      0.15      0.24       393\n\n    accuracy                           0.81      2000\n   macro avg       0.70      0.56      0.57      2000\nweighted avg       0.77      0.81      0.76      2000\n\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1740607047371
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 8: Deploy Model on Azure Machine Learning**\n",
        "Once the model is trained, we deploy it using Azure ML to enable real-time predictions.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(model, \"banking_churn_model.pkl\")\n",
        "\n",
        "print(\"Model saved successfully.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model saved successfully.\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1740607643958
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Get the current directory\n",
        "print(\"Current working directory:\", os.getcwd())\n",
        "\n",
        "# List all files in the directory\n",
        "print(\"Files in directory:\", os.listdir())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Current working directory: /mnt/batch/tasks/shared/LS_root/mounts/clusters/bank-churn-ml-instance/code/Users/rawatp181\nFiles in directory: ['.amlignore', '.amlignore.amltmp', '.ipynb_aml_checkpoints', 'Banking Customer Churn Prediction.ipynb', 'banking customer churn prediction.ipynb.amltmp', 'banking_churn_model.pkl']\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1740607839342
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# List all files in the directory\n",
        "print(\"Files in the current directory:\\n\", os.listdir())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Files in the current directory:\n ['.amlignore', '.amlignore.amltmp', '.ipynb_aml_checkpoints', 'Banking Customer Churn Prediction.ipynb', 'banking customer churn prediction.ipynb.amltmp', 'banking_churn_model.pkl']\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1740607942083
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Define source and destination paths\n",
        "source_file = \"banking_churn_model.pkl\"\n",
        "destination_path = os.path.join(os.getcwd(), source_file)  # Move it to the current working directory\n",
        "\n",
        "# Move the file\n",
        "shutil.move(source_file, destination_path)\n",
        "\n",
        "print(f\"✅ Model moved successfully! Now download it from: {destination_path}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "✅ Model moved successfully! Now download it from: /mnt/batch/tasks/shared/LS_root/mounts/clusters/bank-churn-ml-instance/code/Users/rawatp181/banking_churn_model.pkl\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1740608113091
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file_path = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/bank-churn-ml-instance/code/Users/rawatp181/banking_churn_model.pkl\"\n",
        "\n",
        "# Check if file exists\n",
        "if os.path.exists(file_path):\n",
        "    print(\"✅ Model file exists at:\", file_path)\n",
        "else:\n",
        "    print(\"❌ Model file not found.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "✅ Model file exists at: /mnt/batch/tasks/shared/LS_root/mounts/clusters/bank-churn-ml-instance/code/Users/rawatp181/banking_churn_model.pkl\n"
        }
      ],
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1740608327547
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "directory_path = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/bank-churn-ml-instance/code/Users/rawatp181/\"\n",
        "\n",
        "# List all files\n",
        "print(\"Files in directory:\\n\", os.listdir(directory_path))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Files in directory:\n ['.amlignore', '.amlignore.amltmp', '.ipynb_aml_checkpoints', 'Banking Customer Churn Prediction.ipynb', 'banking customer churn prediction.ipynb.amltmp', 'banking_churn_model.pkl']\n"
        }
      ],
      "execution_count": 32,
      "metadata": {
        "gather": {
          "logged": 1740608344583
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "source_path = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/bank-churn-ml-instance/code/Users/rawatp181/banking_churn_model.pkl\"\n",
        "destination_path = \"/mnt/data/banking_churn_model.pkl\"\n",
        "\n",
        "try:\n",
        "    shutil.move(source_path, destination_path)\n",
        "    print(\"✅ Model moved successfully. Now download it from /mnt/data/\")\n",
        "except Exception as e:\n",
        "    print(\"❌ Error:\", e)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "❌ Error: [Errno 2] No such file or directory: '/mnt/data/banking_churn_model.pkl'\n"
        }
      ],
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1740608357007
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "source_path = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/bank-churn-ml-instance/code/Users/rawatp181/banking_churn_model.pkl\"\n",
        "destination_path = \"/mnt/data/banking_churn_model.pkl\"\n",
        "\n",
        "# Check if source file exists\n",
        "if os.path.exists(source_path):\n",
        "    print(\"✅ Source file exists.\")\n",
        "else:\n",
        "    print(\"❌ Source file does NOT exist.\")\n",
        "\n",
        "# Check write permission in destination\n",
        "if os.access(\"/mnt/data/\", os.W_OK):\n",
        "    print(\"✅ Write permission available in /mnt/data/\")\n",
        "else:\n",
        "    print(\"❌ No write permission in /mnt/data/\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "✅ Source file exists.\n❌ No write permission in /mnt/data/\n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1740608405014
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "source_path = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/bank-churn-ml-instance/code/Users/rawatp181/banking_churn_model.pkl\"\n",
        "zip_path = os.path.expanduser(\"~/banking_churn_model.zip\")  # Save zip in home directory\n",
        "\n",
        "try:\n",
        "    shutil.make_archive(zip_path.replace(\".zip\", \"\"), 'zip', os.path.dirname(source_path))\n",
        "    print(f\"✅ Model zipped successfully! Download it from: {zip_path}\")\n",
        "except Exception as e:\n",
        "    print(\"❌ Error:\", e)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "✅ Model zipped successfully! Download it from: /home/azureuser/banking_churn_model.zip\n"
        }
      ],
      "execution_count": 36,
      "metadata": {
        "gather": {
          "logged": 1740608718243
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# List all directories and files in your working directory\n",
        "print(\"Current working directory:\", os.getcwd())\n",
        "print(\"Files in directory:\", os.listdir(os.getcwd()))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Current working directory: /mnt/batch/tasks/shared/LS_root/mounts/clusters/bank-churn-ml-instance/code/Users/rawatp181\nFiles in directory: ['.amlignore', '.amlignore.amltmp', '.ipynb_aml_checkpoints', 'Banking Customer Churn Prediction.ipynb', 'banking customer churn prediction.ipynb.amltmp', 'banking_churn_model.pkl']\n"
        }
      ],
      "execution_count": 37,
      "metadata": {
        "gather": {
          "logged": 1740608895320
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "source_path = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/bank-churn-ml-instance/code/Users/rawatp181/banking_churn_model.pkl\"\n",
        "destination_path = \"/mnt/data/banking_churn_model.pkl\"\n",
        "\n",
        "try:\n",
        "    shutil.copy(source_path, destination_path)\n",
        "    print(f\"✅ File copied successfully! Download it from: {destination_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error copying file: {e}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "❌ Error copying file: [Errno 2] No such file or directory: '/mnt/data/banking_churn_model.pkl'\n"
        }
      ],
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1740608958161
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Load the Trained Model & Test Data**\n",
        "\n",
        "In this step, we will:\n",
        "- Load the trained churn prediction model (`.pkl` file) from Azure Notebook.\n",
        "- Load the test dataset (`CSV` file).\n",
        "- Select the required features for predictions.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"banking_churn_model.pkl\", \"rb\") as file:\n",
        "    content = file.read(10)  # Read first 10 bytes to check if it's a valid pickle\n",
        "print(content)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "b'\\x80\\x04\\x95\\t\\x02\\x00\\x00\\x00\\x00\\x00'\n"
        }
      ],
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1740612915775
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the model properly again\n",
        "model_filename = \"banking_churn_model.pkl\"\n",
        "with open(model_filename, \"wb\") as file:\n",
        "    pickle.dump(model, file)\n",
        "\n",
        "print(\"Model saved successfully!\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model saved successfully!\n"
        }
      ],
      "execution_count": 42,
      "metadata": {
        "gather": {
          "logged": 1740612967054
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file_size = os.path.getsize(\"banking_churn_model.pkl\")\n",
        "print(f\"File size: {file_size} bytes\")\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "File size: 755 bytes\n"
        }
      ],
      "execution_count": 44,
      "metadata": {
        "gather": {
          "logged": 1740613033851
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())  # Print the current working directory\n",
        "print(os.listdir())  # List all files in the directory\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/mnt/batch/tasks/shared/LS_root/mounts/clusters/bank-churn-ml-instance/code/Users/rawatp181\n['.amlignore', '.amlignore.amltmp', '.ipynb_aml_checkpoints', 'Banking Customer Churn Prediction.ipynb', 'banking customer churn prediction.ipynb.amltmp', 'banking_churn_model.pkl']\n"
        }
      ],
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1740613044151
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Load the model\n",
        "with open(\"banking_churn_model.pkl\", \"rb\") as file:\n",
        "    model = pickle.load(file)\n",
        "\n",
        "print(\"✅ Model loaded successfully!\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "✅ Model loaded successfully!\n"
        }
      ],
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1740613264977
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Print current working directory\n",
        "print(\"Current Directory:\", os.getcwd())\n",
        "\n",
        "# List all files in the directory\n",
        "print(\"Files Available:\", os.listdir())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Current Directory: /mnt/batch/tasks/shared/LS_root/mounts/clusters/bank-churn-ml-instance/code/Users/rawatp181\nFiles Available: ['.amlignore', '.amlignore.amltmp', '.ipynb_aml_checkpoints', 'Banking Customer Churn Prediction.ipynb', 'banking customer churn prediction.ipynb.amltmp', 'banking_churn_model.pkl']\n"
        }
      ],
      "execution_count": 48,
      "metadata": {
        "gather": {
          "logged": 1740613332317
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}